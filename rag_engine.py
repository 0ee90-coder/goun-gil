"""
ğŸ¯ ì¢…ë¡œêµ¬ ê´€ê´‘ ì½”ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ RAG Engine (ìµœì í™” ë²„ì „)
- ë²¡í„°ìŠ¤í† ì–´ ì¤‘ë³µ ì œê±°
- RAG ê²€ìƒ‰ ë‹¤ì–‘ì„± ë³´ì¥ (MMR)
- TSP ê²½ë¡œ ìµœì í™”
- Content ê¸°ë°˜ ì¶”ì²œ
- Streamlit ì™„ë²½ í˜¸í™˜
"""

import json
import os
import math
import re
from itertools import permutations
from typing import List, Dict, Tuple, Optional
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class TourRecommendationEngine:
    """ê´€ê´‘ ì½”ìŠ¤ ì¶”ì²œ ì—”ì§„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # API í‚¤ í™•ì¸ (Streamlit secrets ìš°ì„ , í™˜ê²½ ë³€ìˆ˜ fallback)
        try:
            import streamlit as st
            api_key = st.secrets.get("OPENAI_API_KEY")
        except:
            api_key = None
        
        if not api_key:
            api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ ë˜ëŠ” .streamlit/secrets.tomlì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
            )
        
        # LLM ì„¤ì •
        self.llm = ChatOpenAI(model="gpt-5.1", temperature=0.7, api_key=api_key)
        self.rerank_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
        
        # ìƒìˆ˜
        self.WALK_SPEED_NORMAL = 4.0
        self.WALK_SPEED_SLOW = 2.5
        
        # ë°ì´í„° ì €ì¥
        self.integrated_data = None
        self.vectorstore = None
        
        print("âœ… RAG Engine ì´ˆê¸°í™” ì™„ë£Œ!")
    
    
    def load_json_with_dedup(self, tour_path: str, cafe_path: str, restaurant_path: str) -> Dict:
        """JSON ë¡œë“œ + ì¤‘ë³µ ì œê±°"""
        def load_and_dedup(path, category_name):
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ì œëª© ê¸°ì¤€ ì¤‘ë³µ ì œê±°
            seen = set()
            unique_data = []
            duplicates = 0
            
            for item in data:
                title = item.get('title', '')
                if title and title not in seen:
                    seen.add(title)
                    unique_data.append(item)
                else:
                    duplicates += 1
            
            print(f"  {category_name}: {len(data)}ê°œ â†’ {len(unique_data)}ê°œ (ì¤‘ë³µ {duplicates}ê°œ ì œê±°)")
            return unique_data
        
        print("\nğŸ“– ë°ì´í„° ë¡œë“œ ì¤‘...")
        tour_data = load_and_dedup(tour_path, "ê´€ê´‘ì§€")
        cafe_data = load_and_dedup(cafe_path, "ì¹´í˜")
        restaurant_data = load_and_dedup(restaurant_path, "ìŒì‹ì ")
        
        integrated = {
            'tour': {item['title']: item for item in tour_data},
            'cafe': {item['title']: item for item in cafe_data},
            'restaurant': {item['title']: item for item in restaurant_data}
        }
        
        print(f"\nâœ… ì´ {len(tour_data) + len(cafe_data) + len(restaurant_data)}ê°œ ì¥ì†Œ ë¡œë“œ ì™„ë£Œ!\n")
        self.integrated_data = integrated
        return integrated
    
    
    def setup_vectorstore(self) -> Chroma:
        """ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥)"""
        if not self.integrated_data:
            raise ValueError("ë¨¼ì € load_json_with_dedup()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")
        
        print("\n" + "="*60)
        print("ğŸ“š ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •")
        print("="*60)
        
        print("ğŸ“ ë¬¸ì„œ ìƒì„± ì¤‘...")
        documents = []
        
        for category_key, category_name in [('tour', 'ê´€ê´‘ì§€'), ('cafe', 'ì¹´í˜'), ('restaurant', 'ìŒì‹ì ')]:
            for title, data in self.integrated_data[category_key].items():
                content = data.get('content', '')
                if content:
                    # facilitiesë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    facilities = data.get('facilities', '')
                    if isinstance(facilities, list):
                        facilities = ', '.join(facilities)
                    
                    # ì¢Œí‘œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    lat = self._extract_coordinate(data, 'latitude')
                    lng = self._extract_coordinate(data, 'longitude')
                    
                    doc = Document(
                        page_content=content,
                        metadata={
                            'title': title,
                            'category': category_name,
                            'address': data.get('address', ''),
                            'content': content,
                            'facilities': facilities,
                            'latitude': lat,
                            'longitude': lng
                        }
                    )
                    documents.append(doc)
        
        print(f"ğŸ“ ì´ {len(documents)}ê°œ ë¬¸ì„œ ìƒì„±")
        
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©)
        print("ğŸ”„ ë²¡í„° ì„ë² ë”© ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        # Chroma í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë©”ëª¨ë¦¬ ì „ìš©)
        import chromadb
        
        # EphemeralClient ì‚¬ìš© (ë©”ëª¨ë¦¬ ì „ìš©, í…Œì´ë¸” ì˜¤ë¥˜ ë°©ì§€)
        chroma_client = chromadb.EphemeralClient()

        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            client=chroma_client,
            collection_name="goun_gil_collection"
        )
        
        print("âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
        return self.vectorstore
    
    
    @staticmethod
    def _extract_coordinate(data: Dict, coord_type: str) -> float:
        """ì¢Œí‘œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ (1_map.pyì™€ ë™ì¼í•œ ë¡œì§)"""
        # 1. coordinates ê°ì²´ì—ì„œ ì°¾ê¸°
        if 'coordinates' in data:
            coords = data['coordinates']
            value = coords.get(coord_type)
            if value:
                try:
                    return float(value)
                except (ValueError, TypeError):
                    pass
        
        # 2. ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì°¾ê¸°
        value = data.get(coord_type)
        if value:
            try:
                return float(value)
            except (ValueError, TypeError):
                pass
        
        # 3. mapx/mapy fallback
        if coord_type == 'longitude':
            value = data.get('mapx')
        elif coord_type == 'latitude':
            value = data.get('mapy')
        
        if value:
            try:
                return float(value)
            except (ValueError, TypeError):
                pass
        
        return 0.0
    
    
    @staticmethod
    def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (km)"""
        R = 6371
        lat1_rad = math.radians(lat1)
        lat2_rad = math.radians(lat2)
        delta_lat = math.radians(lat2 - lat1)
        delta_lon = math.radians(lon2 - lon1)
        
        a = math.sin(delta_lat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon/2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c
    
    
    def openai_rerank(self, query: str, documents: List, top_k: int = 10) -> List:
        """OpenAI ê¸°ë°˜ Reranker"""
        if len(documents) == 0:
            return []
        
        if len(documents) <= top_k:
            return documents
        
        doc_list = "\n".join([
            f"{i+1}. {doc.metadata.get('title', 'Unknown')}: {doc.metadata.get('content', '')[:100]}"
            for i, doc in enumerate(documents)
        ])
        
        prompt = f"""
ì¿¼ë¦¬: {query}

ë¬¸ì„œ ëª©ë¡:
{doc_list}

ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìƒìœ„ {top_k}ê°œì˜ ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.
ì˜ˆ: 3,1,5,2,7,4,9,6,8,10
"""
        
        try:
            response = self.rerank_llm.invoke(prompt)
            indices = [int(x.strip())-1 for x in response.content.strip().split(',')]
            reranked = [documents[i] for i in indices if 0 <= i < len(documents)]
            return reranked[:top_k]
        except Exception as e:
            print(f"âš ï¸ Reranker ì˜¤ë¥˜: {e}")
            return documents[:top_k]
    
    
    def search_places(self, user_type: str, trip_purpose: str, category: str, 
                     region: Optional[str] = None, top_k: int = 10) -> List[Dict]:
        """ì¥ì†Œ ê²€ìƒ‰ + ì¤‘ë³µ ì œê±° + ë‹¤ì–‘ì„± ë³´ì¥ + ì§€ì—­ í•„í„°ë§"""
        if not self.vectorstore:
            raise ValueError("ë¨¼ì € setup_vectorstore()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")
        
        if isinstance(trip_purpose, list):
            trip_purpose = " ".join(trip_purpose)
        
        query = f"{user_type}ì—ê²Œ ì í•©í•œ {trip_purpose} ë¶„ìœ„ê¸°ì˜ {category}. ì ‘ê·¼ì„±ì´ ì¢‹ê³  ì‹œì„¤ì´ ì˜ ê°–ì¶°ì§„ ê³³."
        
        # ì§€ì—­ í•„í„° ì¶”ê°€
        search_kwargs = {
            "k": 50,
            "fetch_k": 100,
            "lambda_mult": 0.7,
            "filter": {"category": category}
        }
        
        retriever = self.vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs=search_kwargs
        )
        
        candidates = retriever.invoke(query)
        
        # ì§€ì—­ í•„í„°ë§ (regionì´ ì§€ì •ëœ ê²½ìš°)
        if region:
            filtered_candidates = [
                doc for doc in candidates 
                if region in doc.metadata.get('address', '')
            ]
            if filtered_candidates:
                candidates = filtered_candidates
                print(f"  {category}: {region} í•„í„° ì ìš© â†’ {len(candidates)}ê°œ")
        
        print(f"  {category}: MMRë¡œ {len(candidates)}ê°œ ê²€ìƒ‰")
        
        # Rerankerë¡œ ì •ë ¬
        reranked = self.openai_rerank(query, candidates, top_k=top_k * 2)
        print(f"  {category}: Rerankerë¡œ {len(reranked)}ê°œ ì •ë ¬")
        
        # ì¤‘ë³µ ì œê±°
        seen_titles = set()
        unique_results = []
        
        for doc in reranked:
            title = doc.metadata.get('title', '')
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_results.append(doc.metadata)
                if len(unique_results) >= top_k:
                    break
        
        print(f"  {category}: ì¤‘ë³µ ì œê±° í›„ {len(unique_results)}ê°œ ìµœì¢… ì„ íƒ\n")
        return unique_results
    
    
    def create_courses(self, user_type: str, trip_purpose: List[str], 
                      region: Optional[str] = None) -> List[Dict]:
        """LLMìœ¼ë¡œ ì½”ìŠ¤ ìƒì„± (Streamlit í˜¸í™˜ ë²„ì „)"""
        print(f"\n{'='*60}")
        print(f"ğŸ¯ {user_type} - {' '.join(trip_purpose)} ë¶„ìœ„ê¸°")
        if region:
            print(f"ğŸ“ ì§€ì—­: {region}")
        print(f"{'='*60}\n")
        
        print("ğŸ” ì¥ì†Œ ê²€ìƒ‰ ì¤‘...")
        tour_list = self.search_places(user_type, trip_purpose, "ê´€ê´‘ì§€", region, 10)
        cafe_list = self.search_places(user_type, trip_purpose, "ì¹´í˜", region, 10)
        restaurant_list = self.search_places(user_type, trip_purpose, "ìŒì‹ì ", region, 10)
        
        print(f"âœ… ì´ {len(tour_list) + len(cafe_list) + len(restaurant_list)}ê°œ ì¥ì†Œ ê²€ìƒ‰ ì™„ë£Œ\n")
        
        # ì›ë³¸ ë°ì´í„°ì—ì„œ ì „ì²´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        def get_full_data(place_name, category_key):
            """ì¥ì†Œ ì´ë¦„ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
            full_data = self.integrated_data[category_key].get(place_name)
            if not full_data:
                print(f"âš ï¸ ê²½ê³ : {category_key}ì—ì„œ '{place_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            return full_data
        
        # LLMìœ¼ë¡œ ì½”ìŠ¤ ìƒì„±
        llm_output, data_dict = self._create_courses_llm(user_type, trip_purpose, 
                                                         tour_list, cafe_list, restaurant_list)
        
        # íŒŒì‹±
        courses = self.parse_llm_result(llm_output, data_dict)
        
        if len(courses) == 0:
            print("âš ï¸ íŒŒì‹± ì‹¤íŒ¨!")
            return []
        
        # TSP ìµœì í™”
        optimized_courses = self.optimize_all_courses(courses, data_dict)
        
        # RAG ì„¤ëª… ìƒì„±
        print("\n" + "="*60)
        print("ğŸ“ RAG ì„¤ëª… ìƒì„±")
        print("="*60)
        
        courses_with_explanation = []
        
        for course in optimized_courses:
            try:
                explained = self.generate_course_explanation(course, data_dict, user_type)
                
                # â­ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¥ì†Œ ì°¾ê¸° + optimized_order ìƒì„±
                tour_place = None
                cafe_place = None
                restaurant_place = None
                optimized_order = []  # ìµœì í™”ëœ ìˆœì„œ ì €ì¥
                
                # placesì˜ êµ¬ì¡° í™•ì¸
                for place in course['places']:
                    # placeê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                    if isinstance(place, dict):
                        place_name = place['name']
                        category = place['category']
                    else:
                        # placeê°€ ë¬¸ìì—´ì´ë©´ data_dictì—ì„œ ì°¾ê¸°
                        print(f"âš ï¸ placeê°€ ë¬¸ìì—´ì…ë‹ˆë‹¤: {place}")
                        place_name = place
                        # data_dictì—ì„œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
                        if place_name in data_dict['tour']:
                            category = 'tour'
                        elif place_name in data_dict['cafe']:
                            category = 'cafe'
                        elif place_name in data_dict['restaurant']:
                            category = 'restaurant'
                        else:
                            print(f"âš ï¸ '{place_name}'ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            continue
                    
                    # optimized_orderì— ìˆœì„œëŒ€ë¡œ ì¶”ê°€
                    optimized_order.append(category)
                    
                    # ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    if category == 'tour':
                        tour_place = get_full_data(place_name, 'tour')
                    elif category == 'cafe':
                        cafe_place = get_full_data(place_name, 'cafe')
                    elif category == 'restaurant':
                        restaurant_place = get_full_data(place_name, 'restaurant')
                
                # 3ê°œ ì¥ì†Œê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
                if not tour_place or not cafe_place or not restaurant_place:
                    print(f"âš ï¸ ì½”ìŠ¤ {course['course_id']}: ì¥ì†Œ ì •ë³´ ëˆ„ë½")
                    print(f"  - ê´€ê´‘ì§€: {'âœ“' if tour_place else 'âœ—'}")
                    print(f"  - ì¹´í˜: {'âœ“' if cafe_place else 'âœ—'}")
                    print(f"  - ìŒì‹ì : {'âœ“' if restaurant_place else 'âœ—'}")
                    continue
                
                # Streamlit í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                streamlit_course = {
                    'course_id': course['course_id'],
                    'title': explained['title'],
                    'explanation': explained['explanation'],
                    'tour': tour_place,
                    'cafe': cafe_place,
                    'restaurant': restaurant_place,
                    'optimized_order': optimized_order  # â­ TSP ìˆœì„œ ì¶”ê°€
                }
                
                courses_with_explanation.append(streamlit_course)
                print(f"âœ” ì½”ìŠ¤ {course['course_id']} ì™„ë£Œ")
                
            except Exception as e:
                print(f"âš ï¸ ì½”ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"\nâœ… ì´ {len(courses_with_explanation)}ê°œ ì½”ìŠ¤ ìƒì„± ì™„ë£Œ!\n")
        return courses_with_explanation
    
    
    def _create_courses_llm(self, user_type: str, trip_purpose: List[str], 
                           tour_list, cafe_list, restaurant_list) -> Tuple[str, Dict]:
        """LLMìœ¼ë¡œ ì½”ìŠ¤ ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ)"""
        def format_places(places):
            return "\n".join([f"- {p['title']}" for p in places])
        
        prompt = f"""
ë‹¹ì‹ ì€ ì¢…ë¡œêµ¬ ì—¬í–‰ ì „ë¬¸ê°€ì˜ˆìš”. {user_type}ë¥¼ ìœ„í•œ 3ê°œ ì½”ìŠ¤ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì: {user_type}
í…Œë§ˆ: {' '.join(trip_purpose)}

[ê´€ê´‘ì§€ í›„ë³´]
{format_places(tour_list)}

[ì¹´í˜ í›„ë³´]
{format_places(cafe_list)}

[ìŒì‹ì  í›„ë³´]
{format_places(restaurant_list)}

ğŸš¨ í•„ìˆ˜ ê·œì¹™:
1. ê° ì½”ìŠ¤ëŠ” ê´€ê´‘ì§€ 1ê°œ + ì¹´í˜ 1ê°œ + ìŒì‹ì  1ê°œ (ì´ 3ê°œ ì¥ì†Œ)
2. âš ï¸âš ï¸âš ï¸ 9ê°œ ì¥ì†Œ ëª¨ë‘ ì‚¬ìš©, ì¤‘ë³µ ì ˆëŒ€ ê¸ˆì§€! âš ï¸âš ï¸âš ï¸
3. ê°€ê¹Œìš´ ì¥ì†Œë¼ë¦¬ ë¬¶ê¸°
4. ì¥ì†Œ ì´ë¦„ì„ ì •í™•íˆ ë³µì‚¬

âš ï¸âš ï¸âš ï¸ ì¶œë ¥ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”! âš ï¸âš ï¸âš ï¸

## ì½”ìŠ¤ 1: [êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ì œëª©ì„ ëŒ€ê´„í˜¸ ì•ˆì— ì‘ì„±]
[ê´€ê´‘ì§€] êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€ ì„œìš¸ê´€
[ì¹´í˜] ì‚¬ë‘ ê³ ê¶ë°•ë¬¼ê´€ ì¹´í˜
[ìŒì‹ì ] ì¬ë™ìˆœë‘ë¶€

## ì½”ìŠ¤ 2: [êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ì œëª©ì„ ëŒ€ê´„í˜¸ ì•ˆì— ì‘ì„±]
[ê´€ê´‘ì§€] êµ­ë¦½ë¯¼ì†ë°•ë¬¼ê´€
[ì¹´í˜] ì„¤ë ˆëŠ”ë§ˆì¤‘
[ìŒì‹ì ] ì¢…ë¡œì§„ë‚™ì§€

## ì½”ìŠ¤ 3: [êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ì œëª©ì„ ëŒ€ê´„í˜¸ ì•ˆì— ì‘ì„±]
[ê´€ê´‘ì§€] ì²­ì™€ëŒ€ì‚¬ë‘ì±„
[ì¹´í˜] ë”ìŠ¤í‚¤
[ìŒì‹ì ] í¥ë‚¨ë¶€ë‘

âš ï¸ ë°˜ë“œì‹œ:
- ì œëª©ì€ [ëŒ€ê´„í˜¸] ì•ˆì— ì‘ì„±
- [ê´€ê´‘ì§€], [ì¹´í˜], [ìŒì‹ì ] í‘œê¸° ì •í™•íˆ ì‚¬ìš©
- ë‹¤ë¥¸ ì„¤ëª… ì¶”ê°€í•˜ì§€ ë§ê³  ìœ„ í˜•ì‹ë§Œ ì¶œë ¥
"""
        
        print("ğŸ¤– LLM ì½”ìŠ¤ ìƒì„± ì¤‘...\n")
        response = self.llm.invoke(prompt)
        
        data_dict = {
            'tour': {item['title']: item for item in tour_list},
            'cafe': {item['title']: item for item in cafe_list},
            'restaurant': {item['title']: item for item in restaurant_list}
        }
        
        return response.content, data_dict
    
    
    def parse_llm_result(self, llm_output: str, data_dict: Dict) -> List[Dict]:
        """LLM ì¶œë ¥ íŒŒì‹± + ì¤‘ë³µ ì²´í¬"""
        print("\n" + "="*60)
        print("ğŸ“‹ LLM ì¶œë ¥ íŒŒì‹±")
        print("="*60)
        
        courses = []
        course_blocks = re.split(r'##\s*ì½”ìŠ¤\s*(\d+):', llm_output)
        
        # ì¤‘ë³µ ì²´í¬ìš©
        used_places = set()
        
        for i in range(1, len(course_blocks), 2):
            course_id = int(course_blocks[i])
            content = course_blocks[i + 1]
            
            # ì œëª© ì¶”ì¶œ
            title_match = re.search(r'\[(.+?)\]', content)
            title = title_match.group(1) if title_match else f"ì½”ìŠ¤ {course_id}"
            
            # ì¥ì†Œ ì¶”ì¶œ
            places = []
            place_pattern = r'\[(ê´€ê´‘ì§€|ì¹´í˜|ìŒì‹ì |ì‹ë‹¹)\]\s*(.+?)(?:\n|$)'
            place_matches = re.findall(place_pattern, content)
            
            for category, name in place_matches:
                name = name.strip()
                
                if 'ê´€ê´‘' in category:
                    category_key = 'tour'
                elif 'ì¹´í˜' in category:
                    category_key = 'cafe'
                elif 'ìŒì‹' in category or 'ì‹ë‹¹' in category:
                    category_key = 'restaurant'
                else:
                    continue
                
                # ì¤‘ë³µ ì²´í¬
                place_id = f"{category_key}:{name}"
                
                if place_id in used_places:
                    print(f"âš ï¸ ì¤‘ë³µ ë°œê²¬: {name}")
                    
                    # êµì²´ ì‹œë„
                    available_places = [
                        p for p in data_dict[category_key].keys()
                        if f"{category_key}:{p}" not in used_places
                    ]
                    
                    if available_places:
                        name = available_places[0]
                        place_id = f"{category_key}:{name}"
                        print(f"   âœ… êµì²´: {name}")
                
                used_places.add(place_id)
                places.append({'category': category_key, 'name': name})
            
            if len(places) >= 3:
                courses.append({
                    'course_id': course_id,
                    'title': title,
                    'places': places[:3]
                })
                
                print(f"\nâœ… ì½”ìŠ¤ {course_id}: {title}")
                for p in places[:3]:
                    print(f"  [{p['category']}] {p['name']}")
        
        return courses
    
    
    def optimize_route(self, places: List[Dict], data_dict: Dict) -> List[Dict]:
        """TSP ìµœì í™”"""
        def get_coords(category: str, name: str):
            place = data_dict[category].get(name)
            if not place:
                raise ValueError(f"{category}ì—ì„œ '{name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return place['latitude'], place['longitude']
        
        all_orders = list(permutations(places))
        best_order = None
        min_distance = float('inf')
        
        for order in all_orders:
            coords = [get_coords(p['category'], p['name']) for p in order]
            
            total_distance = 0
            for i in range(len(coords) - 1):
                lat1, lon1 = coords[i]
                lat2, lon2 = coords[i + 1]
                total_distance += self.haversine_distance(lat1, lon1, lat2, lon2)
            
            if total_distance < min_distance:
                min_distance = total_distance
                best_order = list(order)
        
        return best_order
    
    
    def optimize_all_courses(self, courses: List[Dict], data_dict: Dict) -> List[Dict]:
        """ëª¨ë“  ì½”ìŠ¤ ìµœì í™”"""
        print("\n" + "="*60)
        print("ğŸš€ ê²½ë¡œ ìµœì í™” (TSP)")
        print("="*60)
        
        optimized_courses = []
        
        for course in courses:
            # optimize_routeëŠ” places ë¦¬ìŠ¤íŠ¸ë¥¼ ì¬ì •ë ¬í•´ì„œ ë°˜í™˜
            best_order = self.optimize_route(course['places'], data_dict)
            
            # â­ best_orderê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¥¼ ìœ ì§€í•˜ë„ë¡ ë³´ì¥
            optimized_courses.append({
                'course_id': course['course_id'],
                'title': course['title'],
                'places': best_order  # ì´ë¯¸ [{'category': '...', 'name': '...'}, ...] í˜•íƒœ
            })
            
            # ìˆœì„œ ì¶œë ¥
            category_names = {'tour': 'ê´€ê´‘ì§€', 'cafe': 'ì¹´í˜', 'restaurant': 'ìŒì‹ì '}
            order_str = " â†’ ".join([category_names.get(p['category'], '?') for p in best_order])
            print(f"âœ” ì½”ìŠ¤ {course['course_id']}: {order_str}")
        
        return optimized_courses
    
    
    def generate_course_explanation(self, course: Dict, data_dict: Dict, user_type: str) -> Dict:
        """RAGë¡œ ì½”ìŠ¤ ì„¤ëª… ìƒì„± (Content ê¸°ë°˜)"""
        
        # ê° ì¥ì†Œì˜ content ê°€ì ¸ì˜¤ê¸°
        places_info = []
        for place in course['places']:
            place_data = data_dict[place['category']].get(place['name'])
            if place_data:
                places_info.append({
                    'name': place_data['title'],
                    'content': place_data.get('content', '')
                })
        
        places_summary = "\n\n".join([
            f"[{p['name']}]\n{p['content']}"
            for p in places_info
        ])
        
        prompt = f"""
ë‹¹ì‹ ì€ ì¢…ë¡œêµ¬ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {user_type}ë¥¼ ìœ„í•œ í•˜ë£¨ ì½”ìŠ¤ë¥¼ ì†Œê°œí•´ì£¼ì„¸ìš”.

ë°©ë¬¸ ì¥ì†Œ:
{places_summary}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

### ì½”ìŠ¤ ì œëª©
ê²½ë³µê¶ì—ì„œ ì¦ê¸°ëŠ” ì˜ˆìˆ ê³¼ ë§›ì˜ ì—¬í–‰

**ì´ ì½”ìŠ¤ì˜ ì¥ì **
1. ë¬¸í™”ìœ ì‚° ê°ìƒ í›„ ì—¬ìœ ë¡œìš´ íœ´ì‹
2. ë„ë³´ ì´ë™ ê°€ëŠ¥í•œ ìµœì ì˜ ë™ì„ 
3. ì „í†µê³¼ í˜„ëŒ€ì˜ ì¡°í™”ë¡œìš´ ê²½í—˜

ê·œì¹™:
- ì¥ì ì€ ë°˜ë“œì‹œ 3ê°œ
- ê° ì¥ì ì€ 10-18ìì˜ ì§§ì€ ëª…ì‚¬í˜• ë¬¸êµ¬
- "1. ", "2. ", "3. " í˜•ì‹ ì‚¬ìš©
- ì¥ì†Œëª…ì„ ì§ì ‘ ì“°ì§€ ë§ ê²ƒ
- ~í•©ë‹ˆë‹¤, ~ìˆìŠµë‹ˆë‹¤ ê°™ì€ ë¬¸ì¥í˜• ê¸ˆì§€
- êµ¬ì²´ì ì¸ í¸ì˜ì‹œì„¤(íœ ì²´ì–´, í™”ì¥ì‹¤ ë“±) ì–¸ê¸‰ ê¸ˆì§€

ì¢‹ì€ ì˜ˆ:
1. ì—­ì‚¬ì  ê±´ì¶•ë¬¼ê³¼ ìì—°ì˜ ì¡°í™”
2. ê°€ê¹Œìš´ ê±°ë¦¬ì˜ í¸ë¦¬í•œ ë™ì„ 
3. ë‹¤ì–‘í•œ ë¬¸í™” ì²´í—˜ ê¸°íšŒ

ë‚˜ìœ ì˜ˆ:
1. ì•„ì´ë“¤ê³¼ í•¨ê»˜ ìì—° ì† ë†€ì´ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë„ˆë¬´ ê¹€)
2. íœ ì²´ì–´ ì ‘ê·¼ì´ ìš©ì´í•©ë‹ˆë‹¤ (í¸ì˜ì‹œì„¤ ì–¸ê¸‰)
"""
        
        response = self.llm.invoke(prompt)
        content = response.content
        
        # ğŸ” ë””ë²„ê¹…: GPT ì‘ë‹µ ì¶œë ¥
        print("\n" + "="*80)
        print(f"ğŸ” [ë””ë²„ê¹…] ì½”ìŠ¤ {course['course_id']} GPT ì›ë³¸ ì‘ë‹µ:")
        print("="*80)
        print(content)
        print("="*80 + "\n")
        
        # ì œëª© ì¶”ì¶œ
        title_match = re.search(r'###\s*ì½”ìŠ¤\s*ì œëª©.*?\n\s*(.+?)(?=\n|$)', content, re.DOTALL)
        if title_match:
            generated_title = title_match.group(1).strip()
            # ëŒ€ê´„í˜¸ ì œê±°
            generated_title = re.sub(r'^\[(.+?)\]$', r'\1', generated_title)
            
            # "ì½”ìŠ¤ ì œëª©", "ì¶”ì²œ ì´ìœ " ê°™ì€ ë©”íƒ€ í…ìŠ¤íŠ¸ ì œê±°
            generated_title = re.sub(r'^(ì½”ìŠ¤\s*ì œëª©|ì¶”ì²œ\s*ì´ìœ )\s*[:\-]?\s*', '', generated_title)
            
            # ì œëª©ì´ ë¹„ì–´ìˆê±°ë‚˜ ë©”íƒ€ í…ìŠ¤íŠ¸ë©´ ê¸°ë³¸ê°’
            if not generated_title or generated_title in ["ì¶”ì²œ ì´ìœ ", "ì½”ìŠ¤ ì œëª©"]:
                generated_title = course.get('title', f"ì½”ìŠ¤ {course['course_id']}")
        else:
            generated_title = course.get('title', f"ì½”ìŠ¤ {course['course_id']}")
        
        print(f"ğŸ“Œ ì¶”ì¶œëœ ì œëª©: {generated_title}\n")
        
        # ì¥ì  ì¶”ì¶œ - ê°œì„ ëœ ì •ê·œì‹
        advantages_match = re.search(r'\*\*ì´\s*ì½”ìŠ¤ì˜\s*ì¥ì \*\*\s*\n(.+?)(?=\n\n|###|$)', content, re.DOTALL)
        if advantages_match:
            advantages_text = advantages_match.group(1).strip()
            print(f"âœ… ì¥ì  ì¶”ì¶œ ì„±ê³µ (ì •ê·œì‹ ë§¤ì¹­)")
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:\n{advantages_text}\n")
        else:
            # fallback
            advantages_text = "1. ì ‘ê·¼ì„±ì´ ìš°ìˆ˜í•œ í¸ë¦¬í•œ ìœ„ì¹˜.\n2. ë‹¤ì–‘í•œ ë³¼ê±°ë¦¬ì™€ ì¦ê¸¸ê±°ë¦¬.\n3. ì¾Œì í•˜ê³  ì•ˆì „í•œ í™˜ê²½."
            print(f"âš ï¸ ì¥ì  ì¶”ì¶œ ì‹¤íŒ¨ - fallback ì‚¬ìš©")
        
        explanation = "**ì´ ì½”ìŠ¤ì˜ ì¥ì **\n" + advantages_text
        
        print(f"ğŸ“Œ ìµœì¢… ì¥ì :\n{explanation}\n")
        print("="*80 + "\n")
        
        return {
            'course_id': course['course_id'],
            'title': generated_title,
            'places': course['places'],
            'explanation': explanation
        }


# Streamlit í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
CourseRecommender = TourRecommendationEngine


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì—”ì§„ ì´ˆê¸°í™”
    engine = TourRecommendationEngine()
    
    # ë°ì´í„° ë¡œë“œ
    engine.load_json_with_dedup(
        './tour_final.json',
        './cafe_final.json',
        './restaurant_final.json'
    )
    
    # ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
    engine.setup_vectorstore()
    
    # ì½”ìŠ¤ ìƒì„±
    result = engine.create_courses(
        user_type="ë³´í–‰ì•½ì",
        trip_purpose=["ì „ì‹œ", "ì˜ˆìˆ "],
        region="ì¢…ë¡œêµ¬"
    )
    
    # ê²°ê³¼ ì¶œë ¥
    for course in result:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ ì½”ìŠ¤ {course['course_id']}: {course['title']}")
        print(f"{'='*60}\n")
        print(f"ğŸ“ ê´€ê´‘ì§€: {course['tour']['title']}")
        print(f"â˜• ì¹´í˜: {course['cafe']['title']}")
        print(f"ğŸ½ï¸ ìŒì‹ì : {course['restaurant']['title']}")
        print(f"\n{course['explanation']}\n")
